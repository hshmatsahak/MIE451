{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MIE 451/1513 Lab 5: Prompt Engineering**"
      ],
      "metadata": {
        "id": "L3iWTWuqjrQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lab uses GPT models hosted by OpenAI and can be completed either by:\n",
        "\n",
        "1.   Copying the prompts into the OpenAI web interface.\n",
        "2.   Acquiring  an API key and running the code.\n",
        "\n",
        "Please see the Assignment PDF for instructions on how to set up the web interface and API key."
      ],
      "metadata": {
        "id": "BUWyJXSY_mf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lab was designed with the help of the following materials. You are encouraged to check these references for more details on prompt engineering:\n",
        "- OpenAI API reference:\n",
        "    - https://platform.openai.com/docs/api-reference/introduction\n",
        "\n",
        "- Prompt engineering guides:\n",
        "    - https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api\n",
        "    - https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/"
      ],
      "metadata": {
        "id": "XDqX0bNK6hZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task Description\n",
        "We will explore prompting styles for the broad task of text classification. Your assignment involves designing an experiment to test various prompting styles for a different natural language (NL) task.\n",
        "\n",
        "**Text classification:** Identify aspects such as sentiment or key topics in spans/collections of text. Example subtasks:\n",
        "  * Sentiment analysis:\n",
        "    * Identify positive/negative attitudes and the strength of these attitudes.\n",
        "    * Identify attitude types from a fixed set such as { \"like\", \"love\", \"hate\", \"value\", ... } or by generating open-world labels (i.e., short, non-predefined tags).\n",
        "  * Identify topics of news articles using either a fixed topic set or open-world labels.\n"
      ],
      "metadata": {
        "id": "wCJXA0tMJBkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#API Setup\n"
      ],
      "metadata": {
        "id": "5LLfJsRlBQI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere\n",
        "!pip install tiktoken\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "Mxe33S61-8Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "import cohere\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "TaOQ3J-E9Msa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wraps text to fit on screen without needing horizontal scrolling\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "td6nvJ8JQy_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uploading your OpenAI API Key\n",
        "#NEVER share API keys with anyone - if your payment information is associated with your key, anyone with your key can charge you!\n",
        "\n",
        "#Paste your API key into the prompt window and hit enter. OPENAI_API_KEY becomes your API key as a string.\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rVtAml5U9Z4c",
        "outputId": "29b1281b-94ba-45f2-a9dc-a54458615b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key = OPENAI_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "byR_gWHROBvZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b9e758bb-7def-4ac6-e990-4111903223a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt gpt-3.5-turbo\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello Gpt.\"}\n",
        "  ],\n",
        "  temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "XtgrX5xcBQC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b984df9-3ec4-413f-e8fa-8d08897925b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code prompts the gpt-3.5-turbo-1106 model which is part of the Chat Completions library.\n",
        "\n",
        "**Messages**: `messages` provides the conversation history as a list of messages. This lab focuses on single turn interactions. In a single turn interaction, the first message describes the system's role and the second message contains the prompt.   \n",
        "\n",
        "The default system role is described by the prompt \"You are a helpful assistant''. We will not be working with alternative system roles in this lab but you are welcome to refer to the API documentation and explore this parameter.\n",
        "\n",
        "The prompt is placed in the `content` field of the second message.\n",
        "\n",
        "**Temperature**: `temperature` ranges from 0 to 2 and determines the randomness of the response. A temperature closer 0 gives less variance in responses but is more likely to produce repeated outputs. A higher temperature increases response randomness. However, even setting `temperature = 0` will not produce deterministic responses.\n",
        "\n",
        "**Response**: By default, one response object is returned in `response.choices[0]`, and the response message is accessed as `response.choices[0].message.content` . See the API for more details on how multiple messages can be returned and what other information is included in the output.\n"
      ],
      "metadata": {
        "id": "DktNSakURA0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Zero-shot prompting"
      ],
      "metadata": {
        "id": "FuNhc3plwAEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero-shot (ZS) prompts, as opposed to few-shot (FS) prompts, do not include examples of expected input and output pairs.\n",
        "\n",
        "Let's create some ZS prompts for text classification. Note, these prompts ignore some of the best practices introduced in the instruction engineering section below - they mainly serve as baselines.\n",
        "\n",
        "**Web interface users:** To obtain an output, paste the prompt (located between the `\"\"\"` multiline string indicators in the API call) into the ChatGPT web application. Though ChatGPT3.5 currently uses a similar model to `gpt-3.5-turbo-1106`, the output may not be exactly the same as below due to randomness during response generation.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WO0m9br7xGeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ZS: Positive/Negative sentiment\n",
        "\n",
        "Task: Given a set of course reviews, identify whether the sentiment of each review is positive or negative."
      ],
      "metadata": {
        "id": "qZFB8IQL6NMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "\n",
        "    For each course review, identify whether the sentiment is positive or negative.\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "XpIHedAEOndu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "aa907cf8-c354-445b-c729-b9c08018971d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Course review 1: Positive\n",
            "Course review 2: Negative\n",
            "Course review 3: Mixed (leaning towards positive)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ZS: Positive/Negative sentiment strength\n",
        "\n",
        "Task: Perform the same task as above, but also identify the strength of each sentiment."
      ],
      "metadata": {
        "id": "Sv7g4N8dBGkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "\n",
        "    For each course review, identify whether the sentiment is positive or negative and the strength of the sentiment.\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "g2yPgXwqlbuf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "e049beaa-a50c-40fe-af50-6891573c9e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Course review 1: The sentiment is positive with a strong strength.\n",
            "\n",
            "Course review 2: The sentiment is negative with a moderate strength.\n",
            "\n",
            "Course review 3: The sentiment is mixed, leaning towards positive, with a moderate strength.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ZS 3: Positive/Negative sentiment, sentiment strength, tags\n",
        "\n",
        "Task: Perform the same task as above, but also add open-world labels (i.e., short, non-predefined tags) about the sentiment of each review."
      ],
      "metadata": {
        "id": "JLio99ERCW47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "\n",
        "    For each course review, identify whether the sentiment is positive or negative and the strength of the sentiment. Describe the sentiment in each review with some tags.\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "d7oKE1SOCV7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "1729ef0d-0168-493c-be64-e95d84ee3e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Course review 1: \n",
            "Sentiment: Positive\n",
            "Strength: Strong\n",
            "Tags: Hands-on approach, practical sessions, deeply enhanced understanding, highly valuable\n",
            "\n",
            "Course review 2: \n",
            "Sentiment: Negative\n",
            "Strength: Moderate\n",
            "Tags: Overwhelming, dense material, fast pace, relevance to real-world applications\n",
            "\n",
            "Course review 3: \n",
            "Sentiment: Mixed\n",
            "Strength: Moderate\n",
            "Tags: Demanding, heavy focus on theory, ultimately rewarding, interested in technicalities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ZS: Adding a \"neutral\" review.\n",
        "\n",
        "Lets add some reviews (4 and 5) with a mixed sentiment. This can cause the LLM to add Neutral sentiment to Positive/Negative, which could be undesirable."
      ],
      "metadata": {
        "id": "EACap_2-H9R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "\n",
        "    Course review 4: \"The course was OK\"\n",
        "\n",
        "    Course review 5: \"I liked some parts of the course and disliked others.\"\n",
        "\n",
        "    For each course review, identify whether the sentiment is positive or negative and the strength of the sentiment. Describe the sentiment in each review with some tags.\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "x6eFFNUfE4_W",
        "outputId": "14ca587e-cd61-4694-a022-c8239166e89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, here are the sentiment analyses for each course review:\n",
            "\n",
            "1. Course review 1: Positive sentiment, strong - The student found the hands-on approach and practical sessions highly valuable, enhancing their understanding of decision support systems. Tags: Positive, Strong\n",
            "\n",
            "2. Course review 2: Negative sentiment, moderate - The student found the course overwhelming due to dense material and fast-paced lectures, despite its real-world relevance. Tags: Negative, Moderate\n",
            "\n",
            "3. Course review 3: Mixed sentiment, moderate - The course was demanding with a heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems. Tags: Mixed, Moderate\n",
            "\n",
            "4. Course review 4: Neutral sentiment - The student found the course to be okay. Tags: Neutral\n",
            "\n",
            "5. Course review 5: Mixed sentiment, mild - The student liked some parts of the course and disliked others. Tags: Mixed, Mild\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instruction Engineering (IE)\n",
        "\n",
        "What are the [best practices](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api) to structure a ZS prompt?\n",
        "\n",
        "So far we've seen two prompt [elements](https://www.lambdatest.com/learning-hub/prompt-engineering): **Instructions** and **Input Data**. In the above prompts, the input data came first and the instructions came at the end. However, it is recommended to:\n",
        "\n",
        "\n",
        "1.   Put instructions at the beginning.\n",
        "2.   Separate prompt components with **delimiters** such as #### or '''':\n",
        "\n",
        "    * Delimiters are typically included during LLM fine-tuning.\n",
        "    * Choose delimiters that do not occur naturally in text, such as ####, ====, etc. .\n",
        "    * Be consistent. For example, if you separate inputs with ####, use the same delimiter for every input.\n",
        "\n",
        "\n",
        "\n",
        "Let's apply these suggestions to ZS 1:\n"
      ],
      "metadata": {
        "id": "7-oSa6WVJJjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IE: Instructions first and delimiters (positive/negative sentiment)\n"
      ],
      "metadata": {
        "id": "cyaTiTWv5ph7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    For each course review, identify whether the sentiment is positive or negative.\n",
        "\n",
        "    Course reviews:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "    ####\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "    ####\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "    ####\n",
        "    ''''\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "HGyOjsjy6A1u",
        "outputId": "56670f8a-6bb1-47a1-fa7f-260dd3d8bc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Course review 1: Positive\n",
            "Course review 2: Negative\n",
            "Course review 3: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IE: Output format and context (Positive/Negative sentiment)"
      ],
      "metadata": {
        "id": "vIk844iePEmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two other common elements of a prompt are **output format** and **context**.\n",
        "\n",
        "For example, we can add **output format** instructions such as \"For review `i`, output \"R`i`: positive\" for positive sentiment and \"R`i`: negative\" for negative sentiment. Separate each review with a newline.\"\n",
        "\n",
        "A prompt can also include **context** that does not constitute an explicit instruction but provides useful information about the task. This distinction can sometimes be ambiguous, so context is often ommited in ZS prompts, though an example of using a separate ZS context component is shown below. Most often, the context component takes the form of few-shot (FS) examples, discussed in the next section.\n",
        "\n",
        "Adding these two components:"
      ],
      "metadata": {
        "id": "KpD-adIoLFiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    For each course review, identify whether the sentiment is positive or negative. For review `i`, output \"R`i`: positive\" for positive sentiment and \"R`i`: negative\" for negative sentiment. Seperate each review with a newline.\n",
        "\n",
        "    Context:\n",
        "    ''''\n",
        "    The results of this sentiment analysis will be used for automated numerical analysis.\n",
        "    ''''\n",
        "\n",
        "    Course reviews:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "    ####\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "    ####\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "    ####\n",
        "    ''''\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "YGo8qdB0K4yv",
        "outputId": "7b34b84f-b8d7-4821-bf63-5385e997eb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1: positive\n",
            "R2: negative\n",
            "R3: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Few-shot prompting\n",
        "Much of the benefits of instruction engineering can also be achieved with few-shot (FS) prompting, which function as context.\n",
        "\n",
        "A FS prompt includes one or more examples of the desired output given an input. Like the input data, it is best to clearly seperate these examples with delimeters and maintain consistent formatting.\n",
        "\n",
        "Let's remove the output format instruction and see if the LLM can infer the desired output format given only a few-shot example (this is demonstration purposes - you could both specify the output format and show the format with examples if needed.)\n",
        "\n",
        "We'll also add a leading output word `output`, which is consistent with the output format shown in the example. Adding this leading word is meant to make the LLM more likely to follow the demonstrated output format."
      ],
      "metadata": {
        "id": "EQRO0bPtFZoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FS: Positive/Negative sentiment"
      ],
      "metadata": {
        "id": "rWJkzyfhJwFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    For each course review, identify whether the sentiment is positive or negative.\n",
        "\n",
        "    Example:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's lectures were insightful, offering a deep dive into decision support systems that was incredibly beneficial.\"\n",
        "    ####\n",
        "    Course review 2: \"MIE451/1513 was kinda rough with the pace and workload, even if it did up my real-world skills.\"\n",
        "    ####\n",
        "\n",
        "    Output:\n",
        "    R1: positive\n",
        "    R2: negative\n",
        "    ''''\n",
        "\n",
        "    Course reviews:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "    ####\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "    ####\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "    ####\n",
        "\n",
        "    Output:\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "8llXYogjQYCR",
        "outputId": "b3d9eb3c-49b1-4a05-a2f0-b97b0850ff74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1: positive\n",
            "R2: negative\n",
            "R3: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FS: Positive/Negative sentiment, sentiment strength\n",
        "Let's add identifying sentiment strength to the task and see if the output format is inferred from the examples."
      ],
      "metadata": {
        "id": "c0D0R4iFXVJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    For each course review, identify whether the sentiment is positive or negative, and the strength of the sentiment.\n",
        "\n",
        "    Example:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's lectures were insightful, offering a deep dive into decision support systems that was incredibly beneficial.\"\n",
        "    ####\n",
        "    Course review 2: \"MIE451/1513 was kinda rough with the pace and workload, even if it did up my real-world skills.\"\n",
        "    ####\n",
        "\n",
        "    Output:\n",
        "    R1: positive, strong\n",
        "    R2: negative, mild\n",
        "    ''''\n",
        "\n",
        "    Course reviews:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "    ####\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "    ####\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "    ####\n",
        "\n",
        "    Output:\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "O2K5X1ixXlnT",
        "outputId": "d50e105d-49c2-4b24-f70b-b83ecade9094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1: positive, strong\n",
            "R2: negative, mild\n",
            "R3: positive, moderate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Bias in FS Examples\n",
        "LLMs are prone to positional bias.\n",
        "\n",
        "In deployed systems, it is best to randomize the order of FS examples. Otherwise, the LLM may infer patterns based on the position of examples - for instance, if all the negative example reviews are at the end, the LLM will be more likely to label the later input reviews as negative."
      ],
      "metadata": {
        "id": "RiJeMG69cxKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Negative Prompts (positive/negative sentiment, sentiment strength)\n",
        "LLMs often fail at understanding negation (e.g., see example 7 [here](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api#h_1f4c9c5fa1)).\n",
        "\n",
        "Let's add back the reivews that are sometimes classified as neuteral (reviews 4 and 5 from before) - this can sometimes lead the model to answer \"Neutral\" instead of positive or negative (sometimes without a sentiment strength). We will try to prevent this behaviour in the next prompts.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q4titFxMZkLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    For each course review, identify whether the sentiment is positive or negative, and the strength of the sentiment.\n",
        "\n",
        "    Example:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's lectures were insightful, offering a deep dive into decision support systems that was incredibly beneficial.\"\n",
        "    ####\n",
        "    Course review 2: \"MIE451/1513 was kinda rough with the pace and workload, even if it did up my real-world skills.\"\n",
        "    ####\n",
        "\n",
        "    Output:\n",
        "    R1: positive, strong\n",
        "    R2: negative, mild\n",
        "    ''''\n",
        "\n",
        "    Course reviews:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "    ####\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "    ####\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "    ####\n",
        "    Course review 4: \"The course was OK\"\n",
        "    ####\n",
        "    Course review 5: \"I liked some parts of the course and disliked others.\"\n",
        "    ####\n",
        "    ''''\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ML1XEGIKU55j",
        "outputId": "dbf97e8a-3163-4a0e-fbeb-ffe7ff4b01fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1: positive, strong\n",
            "R2: negative, mild\n",
            "R3: positive, mild\n",
            "R4: neutral\n",
            "R5: neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "To prevent \"neutral\" outputs, we could tell the model \"Do not include neutral as a sentiment.\" However, due to the difficulty LLMs have with understanding negation, this negative prompt aove could lead the LLM to continue to output \"neutral\", or worse, not classify all of the reviews.\n"
      ],
      "metadata": {
        "id": "OYZg99BYBoEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    For each course review, identify whether the sentiment is positive or negative, and the strength of the sentiment. Do not include neutral as a sentiment.\n",
        "\n",
        "    Example:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's lectures were insightful, offering a deep dive into decision support systems that was incredibly beneficial.\"\n",
        "    ####\n",
        "    Course review 2: \"MIE451/1513 was kinda rough with the pace and workload, even if it did up my real-world skills.\"\n",
        "    ####\n",
        "\n",
        "    Output:\n",
        "    R1: positive, strong\n",
        "    R2: negative, mild\n",
        "    ''''\n",
        "\n",
        "    Course reviews:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "    ####\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "    ####\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "    ####\n",
        "    Course review 4: \"The course was OK\"\n",
        "    ####\n",
        "    Course review 5: \"I liked some parts of the course and disliked others.\"\n",
        "    ####\n",
        "    ''''\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "6KdsAARU2mKA",
        "outputId": "e038e8f5-04a7-4467-91e6-1474f4a84781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1: positive, strong\n",
            "R2: negative, mild\n",
            "R3: positive, mild\n",
            "R4: neutral\n",
            "R5: neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead, we could try to add an example demonstrating the desired behaviour for the neutral case:"
      ],
      "metadata": {
        "id": "Euxl8xyrba7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    For each course review, identify whether the sentiment is positive or negative, and the strength of the sentiment.\n",
        "\n",
        "    Example:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's lectures were insightful, offering a deep dive into decision support systems that was incredibly beneficial.\"\n",
        "    ####\n",
        "    Course review 2: \"MIE451/1513 was kinda rough with the pace and workload, even if it did up my real-world skills.\"\n",
        "    ####\n",
        "    Course review 3: \"Neutral\"\n",
        "    ####\n",
        "\n",
        "    Output:\n",
        "    R1: positive, strong\n",
        "    R2: negative, mild\n",
        "    R3: negative, mild\n",
        "    ''''\n",
        "\n",
        "    Course reviews:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "    ####\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "    ####\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "    ####\n",
        "    Course review 4: \"The course was OK\"\n",
        "    ####\n",
        "    Course review 5: \"I liked some parts of the course and disliked others.\"\n",
        "    ####\n",
        "    ''''\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "_YI8hjuZbQgt",
        "outputId": "a9198a58-b085-46f6-8d87-7920edcd5459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1: positive, strong\n",
            "R2: negative, mild\n",
            "R3: positive, mild\n",
            "R4: negative, mild\n",
            "R5: neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could also add instructions for handling negative behaviour cases (avoiding saying what not to do). For example, we could add the instruction:\n",
        "\n",
        "\"For any review R`j` with sentiment best described as neutral, output \"R`j`: negative, mild\"."
      ],
      "metadata": {
        "id": "xpQgNfZXb6KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    For each course review, identify whether the sentiment is positive or negative, and the strength of the sentiment. For any review R`j` with sentiment best described as neutral, output \"R`j`: negative, mild\".\n",
        "\n",
        "    Example:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's lectures were insightful, offering a deep dive into decision support systems that was incredibly beneficial.\"\n",
        "    ####\n",
        "    Course review 2: \"MIE451/1513 was kinda rough with the pace and workload, even if it did up my real-world skills.\"\n",
        "    ####\n",
        "\n",
        "    Output:\n",
        "    R1: positive, strong\n",
        "    R2: negative, mild\n",
        "    ''''\n",
        "\n",
        "    Course reviews:\n",
        "    ''''\n",
        "    ####\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "    ####\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "    ####\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "    ####\n",
        "    Course review 4: \"The course was OK\"\n",
        "    ####\n",
        "    Course review 5: \"I liked some parts of the course and disliked others.\"\n",
        "    ####\n",
        "    ''''\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "XwyrwpeJcRI_",
        "outputId": "7b1ccf9f-5b4e-43ef-980e-566c429f89d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1: positive, strong\n",
            "R2: negative, mild\n",
            "R3: negative, mild\n",
            "R4: negative, mild\n",
            "R5: negative, mild\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieval-Augmented Generation (RAG)\n",
        "An LLM contains a lot of internal knowledge (in the neural network parameters) it has obtained from its training data. However, sometimes, external knowledge (not in the LLM parameters) is required for a task.\n",
        "\n",
        "To address such tasks, information first needs to be retrieved, and then used for text generation in a process called retrieval-augmented generation (RAG). There are several RAG methods available (see [this survey](https://arxiv.org/pdf/2302.07842.pdf) on augmented language models if you're curious), but we will cover the most basic method which is sometimes called [In-Context RAG](https://arxiv.org/pdf/2302.00083.pdf).\n",
        "\n",
        "In this method, if a query is given as part of a task, it is used to perform a search and the top results are pasted into the LLM prompt with instructions on how to use them for generation. If a search query is not given as part of the task, this query must be generated.\n"
      ],
      "metadata": {
        "id": "jySObxUVXnDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG Example\n",
        "\n",
        "As an example, let's consider the task of identifing the 2023 nobel prize recipients' names and the reasons for each award, and outputing the names and reasons as a comma seperated list.\n",
        "\n",
        "The LLM should not have internal knowledge of these prizes since they were announced on Oct 2nd, 2023, and the `gpt-3.5-turbo-1106` training data cutoff is Sep 2021. Let's check:"
      ],
      "metadata": {
        "id": "mNHt_s1Oaz4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    Identify the 2023 nobel prize recipients' names and the reasons for each award.\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CDNGrtIDhkeh",
        "outputId": "24c20919-c705-40e4-fab0-423213fca4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I cannot provide real-time information about future Nobel Prize recipients as the Nobel Prize winners for 2023 have not been announced yet. The Nobel Prize winners are typically announced in October each year. I recommend checking the official Nobel Prize website or reputable news sources for the most up-to-date information on Nobel Prize recipients.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's generate a query based on the task:"
      ],
      "metadata": {
        "id": "_C8hmwmZizpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    Generate a Google search query for the following task.\n",
        "\n",
        "    Task\n",
        "    ''''\n",
        "    Identify the 2023 nobel prize recipients' names and the reasons for each award.\n",
        "    ''''\n",
        "\n",
        "    Query:\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RV6z9FBSiBh-",
        "outputId": "a15a993e-f031-4df9-a0c2-c6faa75861b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"2023 Nobel Prize winners list and reasons\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, aftering running a Google search with this query, we can copy and paste the top result into the following prompt, which also uses a format example, delimiters, and a leading output word."
      ],
      "metadata": {
        "id": "VamjK4d6i-kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    Use the news article to identify the 2023 nobel prize recipients' names and the reasons for each award. For each award, output a comma seperated list of names and a comma seperated list of keyphrases for the award reason.\n",
        "\n",
        "    Format example:\n",
        "    ''''\n",
        "    {\n",
        "       \"prize name 1\": {\n",
        "            \"recipient names\": [],\n",
        "            \"keyphrases\": []\n",
        "       },\n",
        "      \"prize name 2\": {\n",
        "           \"recipient names\": [],\n",
        "           \"keyphrases\": []\n",
        "       }\n",
        "    }\n",
        "\n",
        "    ''''\n",
        "\n",
        "    News article\n",
        "    ''''\n",
        "Skip to content\n",
        "\n",
        "    Nobel Prizes & Laureates\n",
        "    Nomination\n",
        "    Alfred Nobel\n",
        "    News & insights\n",
        "    Events\n",
        "    Educational\n",
        "\n",
        "Statue of Alfred Nobel.\n",
        "\n",
        "Photo: A. Mahmoud\n",
        "NOBEL PRIZES 2023\n",
        "The Nobel Prize in Physics 2023\n",
        "Pierre Agostini\n",
        "“for experimental methods that generate attosecond pulses of light for the study of electron dynamics in matter”\n",
        "Pierre Agostini\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "Ferenc Krausz\n",
        "“for experimental methods that generate attosecond pulses of light for the study of electron dynamics in matter”\n",
        "Ferenc Krausz\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "Anne L’Huillier\n",
        "“for experimental methods that generate attosecond pulses of light for the study of electron dynamics in matter”\n",
        "Anne L'Huillier\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "Experiments with light capture the shortest of moments\n",
        "The three Nobel Prize laureates in physics 2023 are being recognised for their experiments, which have given humanity new tools for exploring the world of electrons inside atoms and molecules. They have demonstrated a way to create extremely short pulses of light that can be used to measure the rapid processes in which electrons move or change energy.\n",
        "Related articles\n",
        "\n",
        "    Press release: The Nobel Prize in Physics 2023\n",
        "    Popular science background: Electrons in pulses of light\n",
        "    Scientific background: “for experimental methods that generate attosecond pulses of light for the study of electron dynamics in matter”\n",
        "\n",
        "Illustration of two electrons, illustrating the Nobel Prize in Physics 2023.\n",
        "\n",
        "© Johan Jarnestad/The Royal Swedish Academy of Sciences\n",
        "The Nobel Prize in Chemistry 2023\n",
        "Moungi G. Bawendi\n",
        "“for the discovery and synthesis of quantum dots”\n",
        "Moungi Bawendi\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "Louis E. Brus\n",
        "“for the discovery and synthesis of quantum dots”\n",
        "Louis Brus\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "Aleksey I. Yekimov\n",
        "“for the discovery and synthesis of quantum dots”\n",
        "Alexei Ekimov\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "They added colour to nanotechnology\n",
        "Moungi G. Bawendi, Louis E. Brus and Aleksey Yekimov are awarded the Nobel Prize in Chemistry 2023 for the discovery and development of quantum dots. These tiny particles have unique properties and now spread their light from television screens and LED lamps. They catalyse chemical reactions and their clear light can illuminate tumour tissue for a surgeon.\n",
        "Related articles\n",
        "\n",
        "    Press release: The Nobel Prize in Chemistry 2023\n",
        "    Popular science background: They added colour to nanotechnology\n",
        "    Scientific background: Quantum dots – seeds of nanoscience\n",
        "\n",
        "An illustration of a bucket of paint with coloured balls beneath it, representing quantum dots.\n",
        "\n",
        "© Johan Jarnestad/The Royal Swedish Academy of Sciences\n",
        "The Nobel Prize in Physiology or Medicine 2023\n",
        "Katalin Karikó\n",
        "“for their discoveries concerning nucleoside base modifications that enabled the development of effective mRNA vaccines against COVID-19”\n",
        "Katalin Karikó\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "Drew Weissman\n",
        "“for their discoveries concerning nucleoside base modifications that enabled the development of effective mRNA vaccines against COVID-19”\n",
        "Drew Weissman\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "They contributed to an unprecedented rate of vaccine development\n",
        "The discoveries by the two Nobel Prize laureates were critical for developing effective mRNA vaccines against COVID-19 during the pandemic that began in early 2020. Through their groundbreaking findings, which have fundamentally changed our understanding of how mRNA interacts with our immune system, the laureates contributed to the unprecedented rate of vaccine development during one of the greatest threats to human health in modern times.\n",
        "\n",
        "Press release: The Nobel Prize in Physiology or Medicine 2023\n",
        "\n",
        "Scientific background: Discoveries concerning nucleoside base modifications that enabled the development of effective mRNA vaccines against COVID-19\n",
        "A blue background with COVID-19 virus and a yellow strand of modified mRNA. Also shown is the chemical structure of pseudouridine, an RNA base that was important in the prize-awarded discovery. The graphic represents the 2023 Nobel Prize in Physiology or Medicine awarded to Katalin Karinkó and Drew Weissman who received the Nobel Prize in Physiology or Medicine for their discoveries concerning nucleoside base modifications that enabled the development of effective mRNA vaccines against COVID-19.\n",
        "\n",
        "© The Nobel Committe for Physiology or Medicine. Ill. Mattias Karlén\n",
        "The Nobel Prize in Literature 2023\n",
        "Jon Fosse\n",
        "“for his innovative plays and prose which give voice to the unsayable”\n",
        "Jon Fosse\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "The Nobel Prize in Literature 2023\n",
        "Jon Fosse\n",
        "The Nobel Prize in Literature 2023 is awarded to the Norwegian author Jon Fosse, “for his innovative plays and prose which give voice to the unsayable.”\n",
        "\n",
        "His immense oeuvre written in Norwegian Nynorsk and spanning a variety of genres consists of a wealth of plays, novels, poetry collections, essays, children’s books and translations. While he is today one of the most widely performed playwrights in the world, he has also become increasingly recognised for his prose.\n",
        "Related articles\n",
        "\n",
        "    Press release: The Nobel Prize in Literature 2023\n",
        "    Biobibliography\n",
        "\n",
        "Author Jon Fosse at his desk\n",
        "\n",
        "Jon Fosse at his desk.\n",
        "\n",
        "Credit: Det Norske Samlaget. Photo: Tove Breistein\n",
        "The Nobel Peace Prize 2023\n",
        "Narges Mohammadi\n",
        "“for her fight against the oppression of women in Iran and her fight to promote human rights and freedom for all”\n",
        "Narges Mohammadi\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "The Nobel Peace Prize 2023\n",
        "“Woman – Life – Freedom”\n",
        "The Norwegian Nobel Committee has decided to award the Nobel Peace Prize 2023 to Narges Mohammadi for her fight against the oppression of women in Iran and her fight to promote human rights and freedom for all.\n",
        "\n",
        "This year’s peace prize also recognises the hundreds of thousands of people who, in the preceding year, have demonstrated against Iran’s theocratic regime’s policies of discrimination and oppression targeting women. The motto adopted by the demonstrators – “Woman – Life – Freedom” – suitably expresses the dedication and work of Narges Mohammadi.\n",
        "Three demonstrating hands. The hand in the middle wears a set of bracelets representing the colours of Iran.\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2023\n",
        "Claudia Goldin\n",
        "“for having advanced our understanding of women’s labour market outcomes”\n",
        "Claudia Goldin\n",
        "\n",
        "Ill. Niklas Elmehed © Nobel Prize Outreach\n",
        "She uncovered key drivers of gender differences in the labour market\n",
        "Over the past century, the proportion of women in paid work has tripled in many high-income countries. This is one of the biggest societal and economic changes in the labour market in modern times, but significant gender differences remain. It was first in the 1980s that a researcher adopted a comprehensive approach to explaining the source of these differences. Claudia Goldin’s research has given us new and often surprising insights into women’s historical and contemporary roles in the labour market.\n",
        "Related articles\n",
        "\n",
        "    Press release: The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2023\n",
        "    Popular science background: History help us understand gender differences in the labour market\n",
        "    Scientific background to Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2023\n",
        "\n",
        "A detective investigating a file cabinet, accompanied by a golden retriever.\n",
        "\n",
        "© Johan Jarnestad/The Royal Swedish Academy of Sciences\n",
        "Explore prizes and laureates\n",
        "Select the category or categories you would like to filter by\n",
        "Physics\n",
        "Chemistry\n",
        "Medicine\n",
        "Literature\n",
        "Peace\n",
        "Economic Sciences\n",
        "Decrease the year by one\n",
        "Choose a year you would like to search in\n",
        "Increase the year by one\n",
        "Sign up for the “Monthly” newsletter\n",
        "\n",
        "Join thousands of global subscribers enjoying the free monthly Nobel Prize highlights, trivia and up-to-date information.\n",
        "\n",
        "Your e-mail address\n",
        "\n",
        "I consent to my email address being used in accordance with the privacy policy.\n",
        "About the Nobel Prize organisation\n",
        "The Nobel Foundation\n",
        "\n",
        "Tasked with a mission to manage Alfred Nobel's fortune and has ultimate responsibility for fulfilling the intentions of Nobel's will.\n",
        "The prize-awarding institutions\n",
        "\n",
        "For more than a century, these academic institutions have worked independently to select Nobel Prize laureates.\n",
        "Nobel Prize outreach activities\n",
        "\n",
        "Several outreach organisations and activities have been developed to inspire generations and disseminate knowledge about the Nobel Prize.\n",
        "\n",
        "    Press\n",
        "    Contact\n",
        "    FAQ\n",
        "\n",
        "    Privacy policy\n",
        "    Technical support\n",
        "    Terms of use\n",
        "\n",
        "    For developers\n",
        "    Media player\n",
        "\n",
        "Join us\n",
        "\n",
        "Facebook Twitter Instagram Youtube\n",
        "\n",
        "    LinkedIn\n",
        "\n",
        "The Nobel Prize\n",
        "Copyright © Nobel Prize Outreach AB 2023\n",
        "\n",
        "    ''''\n",
        "\n",
        "    Output:\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "FT-jqwK-bSio",
        "outputId": "2b225bbb-f432-4d02-e944-d2764aec92ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "   \"The Nobel Prize in Physics 2023\": {\n",
            "        \"recipient names\": [\"Pierre Agostini\", \"Ferenc Krausz\", \"Anne L’Huillier\"],\n",
            "        \"keyphrases\": [\"experimental methods\", \"attosecond pulses of light\", \"study of electron dynamics in matter\"]\n",
            "   },\n",
            "  \"The Nobel Prize in Chemistry 2023\": {\n",
            "       \"recipient names\": [\"Moungi G. Bawendi\", \"Louis E. Brus\", \"Aleksey I. Yekimov\"],\n",
            "       \"keyphrases\": [\"discovery and synthesis\", \"quantum dots\"]\n",
            "   },\n",
            "   \"The Nobel Prize in Physiology or Medicine 2023\": {\n",
            "       \"recipient names\": [\"Katalin Karikó\", \"Drew Weissman\"],\n",
            "       \"keyphrases\": [\"discoveries concerning nucleoside base modifications\", \"development of effective mRNA vaccines against COVID-19\"]\n",
            "   },\n",
            "   \"The Nobel Prize in Literature 2023\": {\n",
            "       \"recipient names\": [\"Jon Fosse\"],\n",
            "       \"keyphrases\": [\"innovative plays and prose\", \"give voice to the unsayable\"]\n",
            "   },\n",
            "   \"The Nobel Peace Prize 2023\": {\n",
            "       \"recipient names\": [\"Narges Mohammadi\"],\n",
            "       \"keyphrases\": [\"fight against the oppression of women in Iran\", \"promote human rights and freedom for all\"]\n",
            "   },\n",
            "   \"The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2023\": {\n",
            "       \"recipient names\": [\"Claudia Goldin\"],\n",
            "       \"keyphrases\": [\"advanced our understanding of women’s labour market outcomes\"]\n",
            "   }\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chain-of-Thought Prompting\n",
        "It often makes sense to break a task down into a sequence of steps when prompting an LLM, which is broadly called chain-of-thought (COT) prompting.\n",
        "\n",
        "Let's look at a slightly modified example from the [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering).\n",
        "\n",
        "The LLM is asked to determine if the students solution is correct, but fails to catch that the student incorrectly used 100x in step 3) instead of 10x.  \n"
      ],
      "metadata": {
        "id": "-zDAoGitdwu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Problem Statement: I'm building a solar power installation and I need help working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost me a flat $100k per year, and an additional $10 / square foot\n",
        "What is the total cost for the first year of operations as a function of the number of square feet.\n",
        "\n",
        "Student's Solution: Let x be the size of the installation in square feet.\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "WS68RuJndtmb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de9b6d7b-05b8-4f57-857f-89bd823ffadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is correct. The total cost for the first year of operations as a function of the number of square feet is indeed 450x + 100,000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead, we can instruct the LLM to follow a chain of reasoning."
      ],
      "metadata": {
        "id": "0chZHJnPo4NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-1106\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\":\n",
        "    \"\"\"\n",
        "    First work out your own solution to the problem.\n",
        "    Then compare your solution to the student's solution and evaluate if the student's solution is correct or not.\n",
        "    Don't decide if the student's solution is correct until you have done the problem yourself.\n",
        "\n",
        "    Problem Statement:\n",
        "    '''\n",
        "    I'm building a solar power installation and I need help working out the financials.\n",
        "    - Land costs $100 / square foot\n",
        "    - I can buy solar panels for $250 / square foot\n",
        "    - I negotiated a contract for maintenance that will cost me a flat $100k per year, and an additional $10 / square foot\n",
        "    What is the total cost for the first year of operations as a function of the number of square feet?\n",
        "    '''\n",
        "\n",
        "    Student's Solution:\n",
        "    '''\n",
        "    Let x be the size of the installation in square feet.\n",
        "    1. Land cost: 100x\n",
        "    2. Solar panel cost: 250x\n",
        "    3. Maintenance cost: 100,000 + 100x\n",
        "    Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "    '''\n",
        "    \"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature = 0.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "gVRDaRbNW1UE",
        "outputId": "b6092f00-5cb3-4e9f-929a-d013a655209c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First, let's work out the total cost for the first year of operations as a function of the number of square feet.\n",
            "\n",
            "My Solution:\n",
            "Let x be the size of the installation in square feet.\n",
            "1. Land cost: $100 * x\n",
            "2. Solar panel cost: $250 * x\n",
            "3. Maintenance cost: $100,000 + $10 * x\n",
            "\n",
            "Total cost: $100 * x + $250 * x + $100,000 + $10 * x\n",
            "Total cost: $350 * x + $100,000\n",
            "\n",
            "Now, let's compare the student's solution to my solution.\n",
            "\n",
            "Student's Solution:\n",
            "Total cost: 450x + 100,000\n",
            "\n",
            "Evaluation:\n",
            "The student's solution is not correct. The student mistakenly added the land cost, solar panel cost, and maintenance cost together without considering the different cost components separately. The correct total cost should be $350 * x + $100,000, as per my solution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This COT prompt led the LLM to correctly identify the student's mistake.\n",
        "\n",
        "Note that COT can be used in combination with FS prompting or RAG."
      ],
      "metadata": {
        "id": "cEqLK56wppxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#More Resources\n",
        "\n",
        "Prompt engineering:\n",
        "\n",
        "* https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\n",
        "\n",
        "* https://platform.openai.com/docs/guides/prompt-engineering\n",
        "\n",
        "How powerful are the best LLMs?\n",
        "\n",
        "* https://arxiv.org/abs/2303.12712\n",
        "\n",
        "Augmented LLMs:\n",
        "\n",
        "* https://arxiv.org/pdf/2302.07842.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "WhE6RDA0nIdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Why not use a small open source model?\n",
        "Why does this lab use OpenAI's hosted models instead of downloading an open source model?\n",
        "\n",
        "TLDR: Because model size matters and it's not feasible to host large models on colab.\n",
        "\n",
        "[Falcon-RW-1B](https://huggingface.co/tiiuae/falcon-rw-1b) (1 billion parameters) is one of the best open source LLMs for its size according to the [huggingface leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) in November 2023. It is roughly the largest model that fits into the 12 GB of RAM on Google colab.\n",
        "\n",
        "In contrast, GPT-3 has over 175 billion paramaters and requires 300+ GB of RAM.\n",
        "\n",
        "Try it yourself and see how well Falcon 1B compares to GPT-3 in terms of speed and performance on one of the prompts from the lab:"
      ],
      "metadata": {
        "id": "4tghAsd27lAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "EDFlenM07kYY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "outputId": "9b2dd38c-ed90-4c95-ec0d-d8aa32492868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "import torch"
      ],
      "metadata": {
        "id": "LhS79mgJ9-sL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7ba2777d-c76b-4560-a06f-ef387a824811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"tiiuae/falcon-rw-1b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "ZbHwrvfV-CdO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7d56fc2f-49f1-49de-96c2-b5eed0d5b456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the prompt should be between the triple quotations\n",
        "sequences = pipeline(\n",
        "    \"\"\"\n",
        "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
        "\n",
        "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
        "\n",
        "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
        "\n",
        "    For each course review, identify whether the sentiment is positive or negative.\n",
        "    \"\"\",\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "for seq in sequences:\n",
        "    print(f\"Result: {seq['generated_text']}\")"
      ],
      "metadata": {
        "id": "crFklU-i-EfU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "961beee0-8178-4954-9b98-8abb483f324d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: \n",
            "    Course review 1: \"MIE451/1513's hands-on approach with practical sessions deeply enhanced my understanding of decision support systems, making it a highly valuable course in my academic journey.\"\n",
            "\n",
            "    Course review 2: \"I found MIE451/1513 to be overwhelming due to the dense material and the fast pace of lectures, despite its relevance to real-world applications.\"\n",
            "\n",
            "    Course review 3: \"The course was quite demanding with its heavy focus on theory, but ultimately rewarding for those interested in the technicalities of decision support systems.\"\n",
            "\n",
            "    For each course review, identify whether the sentiment is positive or negative.\n",
            "                                                             \n"
          ]
        }
      ]
    }
  ]
}