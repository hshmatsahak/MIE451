{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IBeCy78aSCrF"},"outputs":[],"source":["%%capture\n","!pip install wget"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlvLXZf5Rbbc"},"outputs":[],"source":["from abc import abstractmethod, ABC\n","import os\n","import wget\n","from pathlib import Path\n","\n","from nltk.tokenize import RegexpTokenizer\n","import re\n","from collections import Counter\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, _BaseNB, _BaseDiscreteNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.exceptions import ConvergenceWarning\n","\n","import pandas as pd\n","import numpy as np\n","from scipy import stats\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import random\n","random.seed()\n","from typing import Tuple, List, Optional, Union, Dict\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n","\n","# Please add necessary imports here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fevhNc7iSfgl"},"outputs":[],"source":["%%capture\n","filename = wget.download(\"https://github.com/MIE451-1513-2023/course-datasets/raw/main/20_newsgroups.zip\", \"20_newsgroups.zip\")\n","!unzip 20_newsgroups.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v7qmpRq53Kwx"},"outputs":[],"source":["## IMPORTANT: DO NOT CHANGE THESE GLOBAL VARIABLES!\n","DATA_DIR = \"20_newsgroups\"\n","ALL_FILES = [pth for pth in Path(DATA_DIR).glob(\"**/*\") if pth.is_file() and not pth.name.startswith(\".\")]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fs6A1ANPRvnb"},"outputs":[],"source":["def clean_file_text(text):\n","    new_text = re.sub(\"Newsgroups:.*?\\n\", \"\", text)\n","    new_text = re.sub(\"Xref:.*?\\n\", \"\", new_text)\n","    new_text = re.sub(\"Path:.*?\\n\", \"\", new_text)\n","    new_text = re.sub(\"Date:.*?\\n\", \"\", new_text)\n","    new_text = re.sub(\"Followup-To:.*?\\n\", \"\", new_text)\n","    new_text = re.sub(\"Lines:.*?\\n\", \"\", new_text)\n","    new_text = re.sub(\"Reply-To:.*?\\n\", \"\", new_text)\n","    new_text = re.sub(\"Message-ID:.*?\\n\", \"\", new_text)\n","    new_text = re.sub(\"From:.*?\\n\", \"\", new_text)\n","    new_text = re.sub(\"NNTP-Posting-Host:.*?\\n\", \"\", new_text)\n","    return new_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAuECBXTRxzF"},"outputs":[],"source":["def corpus_count_words(file_list):\n","    tokenizer = RegexpTokenizer(r\"\\w+\")\n","    word_counter = Counter()\n","    for file_path in file_list:\n","        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n","            file_data = file.read()\n","            file_data = clean_file_text(file_data)\n","            file_words = tokenizer.tokenize(file_data)\n","            word_counter.update(file_words)\n","    return word_counter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOsik8k4R355"},"outputs":[],"source":["def get_topic_name(file_path):\n","    return file_path.parent.name\n","\n","def get_target(topic_name):\n","    topics = [\"talk.politics.mideast\", \"rec.autos\", \"comp.sys.mac.hardware\", \"alt.atheism\", \"rec.sport.baseball\", \n","     \"comp.os.ms-windows.misc\", \"rec.sport.hockey\", \"sci.crypt\", \"sci.med\", \"talk.politics.misc\", \n","     \"rec.motorcycles\", \"comp.windows.x\", \"comp.graphics\", \"comp.sys.ibm.pc.hardware\", \"sci.electronics\",\n","     \"talk.politics.guns\", \"sci.space\", \"soc.religion.christian\", \"misc.forsale\", \"talk.religion.misc\"]\n","    return topics.index(topic_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oT6__eoJR5FS"},"outputs":[],"source":["def plot_confusion_matrix(cm):\n","    # plot the confusion matrix\n","    plt.figure(figsize=(10,10))\n","    plt.matshow(cm, fignum=1)\n","    \n","    # add labels for all targets\n","    num_targets = cm.shape[0]\n","    plt.xticks(list(range(num_targets+1)))\n","    plt.yticks(list(range(num_targets+1)))"]},{"cell_type":"markdown","metadata":{"id":"1V7hHUYcFItZ"},"source":["## Q1: Binary Encoding"]},{"cell_type":"markdown","metadata":{"id":"FDK906n_eow6"},"source":["### Q1 (a)\n","\n","[Write your text answer here]"]},{"cell_type":"markdown","metadata":{"id":"tpXVX5UcevT6"},"source":["### Q1 (b)\n","\n","Complete the *train_and_predict* method of the *Classifier* class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fN9q9aBMRh69"},"outputs":[],"source":["class Classifier(ABC):\n","    \"\"\"\n","    Defines the super class that all classifier classes have to inherit.\n","    This class requires one argument 'model_cls' which should be the sklearn classfication algorithm class.\n","    For example, 'LogisticRegression' or 'MultinomialNB' can be used.\n","    \"\"\"\n","    _X, _y = None, None      # Class variables that store features and labels \n","\n","    def __init__(self, model_cls):\n","        self._model_cls = model_cls\n","        \n","    @abstractmethod\n","    def get_dataset(\n","            self, file_list, num_words=1000\n","    ) -> Tuple[pd.DataFrame, List[int]]:\n","        \"\"\"\n","        Returns the tuple (X, y) where X is the feature set and y is the label.\n","        This is an abstract method which has to be implemented in subclasses.\n","\n","        Args:\n","            file_list (List[int]): The list containing file names to process.\n","            num_words (int): The number of words (terms) to be used as features\n","              Note that the feature dataframe you create should have the number \n","              of columns the same as 'num_words'.\n","        \n","        Returns:\n","            X (pd.DataFrame), y (List[int])\n","        \"\"\"\n","        pass\n","    \n","    # DO NOT ADD TO OR MODIFY THE ARGUMENTS AND THE KEYWORD ARGUMENTS TO THIS METHOD!!\n","    def train_and_predict(\n","            self, file_list=None, X=None, y=None, test_size=0.3, random_state=22, **model_kwargs\n","    ) -> Tuple[Dict, Dict]:\n","        \"\"\"\n","        Complete this method for Q1(b).\n","\n","        This method (1) constructs the dataset; (2) splits it into train/test sets;\n","        (3) trains a multi-class classifier model with the type 'self._model_cls';\n","        (4) evaluates the trained model with the test set; \n","        (5) and finally returns the dataset and accuracy information as dictionaries.\n","\n","        \"\"\"\n","        # This method can also be used with an already-built dataset (X, y)\n","        if file_list is None:\n","            assert X is not None and y is not None, \"Either 'file_list' or (X, y) should be provided\"\n","\n","        # Get the dataset (features and labels) if not provided\n","        if X is None or y is None:\n","            X, y = self.get_dataset(file_list)\n","\n","        ####### TODO: Q1(b) #######\n","        # Split the dataset to train and test sets.\n","        # Hint: \n","        #   Make a proper call to the 'train_test_split' function with 'test_size' \n","        #   and 'random_state' passed as arguments. Store the resulting sets into \n","        #   'X_train', 'X_test', 'y_train', 'y_test'.\n","        X_train, X_test, y_train, y_test = None, None, None, None\n","        \n","        ####################\n","\n","        ####### TODO: Q1(b) #######\n","        # Train a classifier of type 'self._model_cls' using the train set.\n","        # Hint:\n","        #   Use 'self._model_cls' while 'model_kwargs' should be passed to \n","        #   its constructor as keyword arguments.  Call the 'fit' function of \n","        #   the classifier with the right pair of (feature, label) to train the model.\n","        #   Store the resulting classifier to 'clf'.\n","        clf = None\n","\n","        ####################\n","\n","        # Make predictions with the train and test sets\n","        y_train_predict = clf.predict(X_train)\n","        y_test_predict = clf.predict(X_test)\n","\n","        ####### TODO: Q1(b) #######\n","        # Calculate the train and test accuracy\n","        # Hint:\n","        #   Use the 'accuracy_score' function and save the respective accuracy to \n","        #   'train_accuracy' and 'test_accuracy'.\n","        train_accuracy = None\n","        test_accuracy = None\n","\n","        ####################\n","\n","        # Values to return\n","        dataset = dict(\n","            X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, \n","        )\n","        info = dict(\n","            y_train_predict=y_train_predict, y_test_predict=y_test_predict,\n","            train_accuracy=train_accuracy, test_accuracy=test_accuracy\n","        )\n","\n","        # Validate return types\n","        assert isinstance(train_accuracy, float) and isinstance(test_accuracy, float), \"incorrect return types\"\n","        assert isinstance(X_train, pd.DataFrame) and isinstance(X_test, pd.DataFrame), \"incorrect return types\"\n","        assert isinstance(y_train, list) and isinstance(y_test, list), \"incorrect return types\"\n","        assert isinstance(y_train_predict, np.ndarray) and isinstance(y_test_predict, np.ndarray), \"incorrect return types\"\n","        \n","        return dataset, info\n","\n","    @staticmethod\n","    def get_performance_ci(\n","            classifier, X=None, y=None, num_tests=10, test_size=0.3, file_list=None\n","    ) -> Tuple[float, float, float, float, float, float]:\n","        if X is None or y is None:\n","            assert file_list is not None, \"When X/y is not passed, you should provide 'file_list'\"\n","            X, y = classifier.get_dataset(file_list)\n","        \n","        # 'train_results' is a list of train accuracy for differrent random splits of the dataset\n","        train_results = []\n","\n","        # 'test_results' is a list of test accuracy for differrent random splits of the dataset\n","        test_results = []\n","\n","        ####### TODO: Q1(e) #######\n","        # Write your code here for Q1(e).\n","        # Hint: \n","        #   First, randomly generate a set of integers to be used as random states using, \n","        #   e.g., 'np.random.randint', 'random.randint', or even np.random.permutation\n","        #   (these functions act differently, so beware of it). \n","        #   Then, you should call the 'classifier.train_and_predict' method by passing \n","        #   the random state, the dataset, and the test_size to get the accuracy results.\n","        #   Notice that you should be able to retrieve the accuracy info from \n","        #   the returned 'info' dictionary. Finally, make sure to retrieve and append \n","        #   the train and test accuracy results to the corresponding lists defined above.\n","\n","        \n","        ####################\n","\n","        # Calculate the train mean and the 95% confidence interval for the list of results\n","        train_mean = np.mean(train_results)\n","        train_ci_low, train_ci_high = stats.t.interval(0.95, len(train_results)-1, loc=train_mean, scale=stats.sem(train_results))\n","\n","        # Calculate the test mean and the 95% confidence interval for the list of results\n","        test_mean = np.mean(test_results)\n","        test_ci_low, test_ci_high = stats.t.interval(0.95, len(test_results)-1, loc=test_mean, scale=stats.sem(test_results))\n","\n","        # Validate return types\n","        assert isinstance(train_mean, float) and isinstance(train_ci_low, float) and isinstance(train_ci_high, float), \"return types\"\n","        assert isinstance(test_mean, float) and isinstance(test_ci_low, float) and isinstance(test_ci_high, float), \"return types\"\n","\n","        return train_mean, train_ci_low, train_ci_high, test_mean, test_ci_low, test_ci_high\n","\n","    @staticmethod\n","    def create_cm(\n","            classifier, X: pd.DataFrame, y: List[int], num_tests: int, test_size=0.3\n","    ) -> np.ndarray:\n","        # 'cm_list' should contain the confusion matrices for different random splits of the dataset\n","        cm_list = []\n","\n","        ####### TODO: Q1(g) #######\n","        # Write your code here for Q1(g).\n","        # Hint: \n","        #   Again, you should generate 'random_state's and pass them to the \n","        #   'classifier.train_and_predict' method along with the dataset ('X' and 'y').\n","        #   Observe that you can get the true labels and the predictions \n","        #   from the returned dictionaries of the method.\n","        #   Make proper calls to the 'confusion_matrix' function and store the \n","        #   results to 'cm_list'. \n","          \n","        ####################\n","\n","        # Sum the confusion matrices and return the combined confusion matrix\n","        combined_cm = np.array(cm_list).sum(axis=0)\n","\n","        # validate return type\n","        assert isinstance(combined_cm, np.ndarray), \"return type\"\n","\n","        return combined_cm\n","\n","    @property\n","    @abstractmethod\n","    def X(self):\n","        pass\n","    \n","    @property\n","    @abstractmethod\n","    def y(self):\n","        pass\n","    \n","    @X.setter\n","    @abstractmethod\n","    def X(self, X):\n","        pass\n","    \n","    @y.setter\n","    @abstractmethod\n","    def y(self, y):\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4_RGDVQhYWE"},"outputs":[],"source":["class ClassifierWithBinaryEncoding(Classifier):\n","\n","    _X, _y = None, None\n","\n","    def __init__(self, model_cls):\n","        super().__init__(\n","            model_cls=model_cls\n","        )\n","\n","    def get_dataset(\n","            self, file_list, num_words=1000\n","    ) -> Tuple[pd.DataFrame, List[int]]:\n","        \"\"\"\n","        Returns the tuple (X, y) where X is the feature set and y is the label.\n","        This method uses the binary encoding for features, where the most common\n","        'num_words' number of terms are used.\n","\n","        Args:\n","            file_list (List[int]): The list containing file names to process.\n","            num_words (int): The number of words (terms) to be used as features\n","              Note that the feature dataframe you create should have the number \n","              of columns the same as 'num_words'.\n","        \n","        Returns:\n","            X (pd.DataFrame), y (List[int])\n","        \"\"\"\n","        if self.X is not None and self.y is not None:\n","            return self.X, self.y\n","        \n","        # Calculate word count in corpus\n","        news_cnt = corpus_count_words(file_list)\n","\n","        # Select the most common numWords\n","        word_list = [word for (word, freq) in news_cnt.most_common(num_words)]\n","\n","        # Create a binary encoding of dataset based on the selected features (X)\n","        tokenizer = RegexpTokenizer(r\"\\w+\")\n","        df_rows = []\n","        for file_path in file_list:\n","            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n","                file_data = file.read()\n","                file_data = clean_file_text(file_data)\n","                file_words = tokenizer.tokenize(file_data)\n","                df_rows.append([1 if word in file_words else 0 for word in word_list])\n","        X = pd.DataFrame(df_rows, index=[str(f) for f in file_list], columns=word_list)\n","\n","        # Create a dataframe of targets (y)\n","        y = [get_target(get_topic_name(file_path)) for file_path in file_list]\n","\n","        self.X = X; self.y = y\n","        \n","        return X, y\n","\n","    @property\n","    def X(self):\n","        return ClassifierWithBinaryEncoding._X\n","    \n","    @property\n","    def y(self):\n","        return ClassifierWithBinaryEncoding._y\n","    \n","    @X.setter\n","    def X(self, X):\n","        ClassifierWithBinaryEncoding._X = X\n","    \n","    @y.setter\n","    def y(self, y):\n","        ClassifierWithBinaryEncoding._y = y"]},{"cell_type":"markdown","metadata":{"id":"ekhaIEa_arbv"},"source":["### Q1 (b) (cont.)\n","\n","Use the following code to compute the train/test accuracy of the baseline model.  Note that you should have correctly implemented the *train_and_predict* method in the *Classifier* class in order to proceed without an error."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VnuPhI49afyT"},"outputs":[],"source":["# Instantiate the classifier\n","q1_b = ClassifierWithBinaryEncoding(model_cls=LogisticRegression)\n","\n","# Construct the dataset and train the classifier\n","X_base, y = q1_b.get_dataset(file_list=ALL_FILES)\n","q1_b_dataset, q1_b_info = q1_b.train_and_predict(\n","    X=X_base, y=y, test_size=0.3, random_state=22, C=1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"844FerMnbcXD"},"outputs":[],"source":["train_accuracy_q1b = q1_b_info['train_accuracy']\n","test_accuracy_q1b = q1_b_info['test_accuracy']\n","\n","# report results\n","print(f\"Train accuracy of the baseline model: {train_accuracy_q1b}\")\n","print(f\"Test accuracy of the baseline model: {test_accuracy_q1b}\")"]},{"cell_type":"markdown","metadata":{"id":"zPbqIDvkfs05"},"source":["### Q1 (c)\n","\n","Implement an improved feature set in the *get_dataset* method of the following class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pfaHm4OsTfN3"},"outputs":[],"source":["class ClassifierWithImprovedBinaryEncoding(ClassifierWithBinaryEncoding):\n","\n","    _X = None\n","\n","    def __init__(self, model_cls):\n","        super().__init__(\n","            model_cls=model_cls\n","        )\n","\n","    def get_dataset(\n","            self, file_list, num_words=1000\n","    ) -> Tuple[pd.DataFrame, List[int]]:\n","        \"\"\"\n","        Returns the tuple (X, y) where X is the feature set and y is the label.\n","        This method uses the binary encoding for features, where the most common\n","        'num_words' number of terms are used. Further, this class should use \n","        improved features than the one given by its super class.\n","\n","        Args:\n","            file_list (List[int]): The list containing file names to process.\n","            num_words (int): The number of words (terms) to be used as features\n","              Note that the feature dataframe you create should have the number \n","              of columns the same as 'num_words'.\n","        \n","        Returns:\n","            X (pd.DataFrame), y (List[int])\n","        \"\"\"\n","        if self.X is not None and self.y is not None:\n","            return self.X, self.y\n","        \n","        X = None\n","        y = self.y      # Could be None if 'ClassifierWithBinaryEncoding.get_dataset()' has not been called\n","\n","        ####### TODO: Q1(c) #######\n","        # Make improvements to the feature set by using any techniques covered in the IR lab.\n","        # Note that you should still use the binary encoding, not term frequencies.\n","        #\n","        # Hint:\n","        #   Please remember to put index for your dataframe as the file name;\n","        #   columns should match with the terms used as features.\n","        #   For example: pd.DataFrame(data, index=[str(f) for f in file_list], columns=[...])\n","        \n","        ####################\n","        # Validate return types\n","        assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"incorrect return types\"\n","\n","        self.X = X; self.y = y\n","        \n","        return X, y\n","    \n","    @property\n","    def X(self):\n","        return ClassifierWithImprovedBinaryEncoding._X\n","    \n","    @X.setter\n","    def X(self, X):\n","        ClassifierWithImprovedBinaryEncoding._X = X\n","    "]},{"cell_type":"markdown","metadata":{"id":"D39bei9YcJSo"},"source":["### Q1 (d)\n","\n","Use the following code to compute the train/test accuracy of the model with improved features.  Note that you should have correctly implemented the *train_and_predict* method in the *Classifier* class in order to proceed without an error."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQM_14hJparE"},"outputs":[],"source":["# Instantiate the classifier\n","q1_c = ClassifierWithImprovedBinaryEncoding(LogisticRegression)\n","\n","# Construct the dataset and train the classifier\n","X_b_improved, y = q1_c.get_dataset(ALL_FILES, num_words=1000)\n","q1_c_dataset, q1_c_info = q1_c.train_and_predict(\n","    X=X_b_improved, y=y, test_size=0.3, random_state=22, C=1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-YO91qScbJ4"},"outputs":[],"source":["# Retrieve and report the results\n","train_accuracy_q1c = q1_c_info['train_accuracy']\n","test_accuracy_q1c = q1_c_info['test_accuracy']\n","\n","print(f\"Train accuracy of the improved model: {train_accuracy_q1c}\")\n","print(f\"Test accuracy of the improved model: {test_accuracy_q1c}\")"]},{"cell_type":"markdown","metadata":{"id":"32odky0vgMbw"},"source":["[Write your text answer here]"]},{"cell_type":"markdown","metadata":{"id":"lDgRUOgngP11"},"source":["### Q1 (e) \n","\n","Implement and complete the *get_performance_ci* method of the *Classifier* class above. "]},{"cell_type":"markdown","metadata":{"id":"Pco8o8L3goZS"},"source":["### Q1 (f)\n","\n","Use the following code to compute the mean accuracy and 95% confidence interval over 10 random splits."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymzv7RgygXXo"},"outputs":[],"source":["train_mean_bin, train_low_bin, train_high_bin, test_mean_bin, test_low_bin, test_high_bin = Classifier.get_performance_ci(q1_c, X_b_improved, y, num_tests=10)\n","print(f\"Average training accuracy over 10 random splits: {train_mean_bin}\")\n","print(f\"Confidence interval for training accuracy over 10 random splits: [{train_low_bin}, {train_high_bin}]\")\n","print(f\"Average test accuracy over 10 random splits: {test_mean_bin}\")\n","print(f\"Confidence interval for test accuracy over 10 random splits: [{test_low_bin}, {test_high_bin}]\")"]},{"cell_type":"markdown","metadata":{"id":"ExBomi7hhdUJ"},"source":["[Write your text answer here]"]},{"cell_type":"markdown","metadata":{"id":"wfhE0iqlgzqo"},"source":["### Q1 (g)\n","\n","Implement and complete the *create_cm* method of *Classifier* class above."]},{"cell_type":"markdown","metadata":{"id":"YN2v32m2jjCK"},"source":["### Q1 (h):\n","\n","Use the following code to produce a confusion matrix for 10 random splits."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P0_zQmOMjpHE"},"outputs":[],"source":["cm10 = Classifier.create_cm(q1_c, X_b_improved, y, num_tests=10, test_size=0.3)\n","plot_confusion_matrix(cm10)"]},{"cell_type":"markdown","metadata":{"id":"BdcHguHQj_LM"},"source":["[Write your text answer here]"]},{"cell_type":"markdown","metadata":{"id":"WB0iFuk9kNPg"},"source":["## Q2: Number of Features"]},{"cell_type":"markdown","metadata":{"id":"9yLSUfdzlFba"},"source":["### Q2 (a)\n","\n","Implement the method *predict_with_varying_num_features* below. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rrVX2JRdgW81"},"outputs":[],"source":["class ClassifierWithVaryingNumFeatures(ClassifierWithImprovedBinaryEncoding):\n","    def __init__(self, model_cls):\n","        super().__init__(\n","            model_cls=model_cls\n","        )\n","    \n","    def predict_with_varying_num_features(\n","            self, \n","            X: pd.DataFrame, \n","            y: List[int], \n","            p_lst: List[float],  # list of percentages of features to use\n","            test_size=0.3, \n","            random_state=22\n","    ) -> pd.DataFrame:\n","        # 'result_list' is a list of tuples (num_features, train_accuracy, test_accuracy)\n","        # where 'num_features' is the number of words used as features\n","        result_list = []\n","\n","        # Note: only use a single train/test split for this evaluation\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            X, y, test_size=test_size, random_state=random_state\n","        )\n","\n","        for p in p_lst:\n","            subset_size = int(p*X.shape[1])\n","            X_train_subset = X_train.iloc[:, 0:subset_size]\n","            X_test_subset = X_test.iloc[:, 0:subset_size]\n","            \n","            ####### TODO: Q2(a) #######\n","            # Write your code here to calculate 'train_accuracy' and 'test_accuracy'\n","            # for the current subset of features.\n","            #\n","            # Hint:\n","            #   Consult how train and test accuracies were computed before\n","            \n","            ####################\n","\n","            train_accuracy = None\n","            test_accuracy = None\n","            \n","            # Add to 'result_list'\n","            result_list.append((p, train_accuracy, test_accuracy))\n","\n","        # Make a dataframe of the results\n","        result_df = pd.DataFrame(result_list, \n","                                 columns=[\"num_features\", \"train_accuracy\", \"test_accuracy\"])\n","\n","        # Validate return type\n","        assert isinstance(result_df, pd.DataFrame), \"return type\"\n","\n","        return result_df\n","        "]},{"cell_type":"markdown","metadata":{"id":"iX3UdIj6lB-T"},"source":["### Q2 (b)\n","\n","Use the following code to plot the train and test accuracy for the different feature set sizes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_t-DUHG2l48"},"outputs":[],"source":["q2 = ClassifierWithVaryingNumFeatures(LogisticRegression)\n","p_lst = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0]\n","feature_num_df = q2.predict_with_varying_num_features(X_b_improved, y, p_lst)\n","\n","feature_num_df.plot(x=\"num_features\", y=[\"train_accuracy\", \"test_accuracy\"])"]},{"cell_type":"markdown","metadata":{"id":"B9l5qCr-lZlQ"},"source":["[Write your answers here]"]},{"cell_type":"markdown","metadata":{"id":"TaXDfHvflekQ"},"source":["## Q3: Hyperparameter Tuning"]},{"cell_type":"markdown","metadata":{"id":"VzeLmsqTljjA"},"source":["### Q3 (a)\n","\n","Complete the _hyperparameter_ function below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IyTLJ7B73f3T"},"outputs":[],"source":["def hyperparameter(\n","    classifier: Classifier, \n","    X: pd.DataFrame, \n","    y: List[int], \n","    param_list: List[float],\n","    test_size: float = 0.3, \n","    random_state: int = 22,\n",") -> pd.DataFrame:\n","    # 'result_list' is a list of tuples (param, train_accuracy, test_accuracy)\n","    # where 'param' is the hyperparameter value used for training.\n","    result_list = []\n","\n","    # Note that this function uses a single train/test split\n","    # If the trends are not clear, try repeating this for multiple random splits\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=test_size, random_state=random_state\n","    )\n","\n","    for param in param_list:\n","        ####### TODO: Q3(a) #######\n","        # Write your code here to calculate 'train_accuracy' and 'test_accuracy' \n","        # for the current hyperparameter value 'param'.\n","        #\n","        # Hint:\n","        #   You can simply use the 'train_and_predict' method of the 'classifier' object.\n","        #   Just figure out how to pass the hyperparameter value correctly to \n","        #   the method such that the classifier uses the hyperparameter.\n","        \n","        ####################\n","        train_accuracy = None\n","        test_accuracy = None\n","\n","        # Add to result_list\n","        result_list.append((param, train_accuracy, test_accuracy))\n","\n","    # Make a dataframe of the results\n","    result_df = pd.DataFrame(result_list, columns=[\"param\", \"train_accuracy\", \"test_accuracy\"])\n","\n","    # validate return type\n","    assert isinstance(result_df, pd.DataFrame), \"return type\"\n","\n","    return result_df"]},{"cell_type":"markdown","metadata":{"id":"BJPRY5KPpr6T"},"source":["### Q3 (b)\n","\n","Use the following code to plot the train and test accuracy from different hyperparameters.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKRzwpqj39-u"},"outputs":[],"source":["param_list = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n","param_df = hyperparameter(\n","    classifier=q1_c,\n","    X=X_b_improved,\n","    y=y,\n","    param_list=param_list,\n","    test_size=0.3,\n","    random_state=22,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoKmchFC55Cx"},"outputs":[],"source":["param_df.plot(x=\"param\", y=[\"train_accuracy\", \"test_accuracy\"], logx=True)"]},{"cell_type":"markdown","metadata":{"id":"TAwEn79UqARh"},"source":["[Write your text answer here]"]},{"cell_type":"markdown","metadata":{"id":"OekUz4CGqFT7"},"source":["## Q4: Feature Encoding (Term Frequency)"]},{"cell_type":"markdown","metadata":{"id":"ziXEdOr4qIt6"},"source":["### Q4 (a)\n","\n","Implement the *get_dataset* method of the _ClassifierWithTFEncoding_ class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsfRXds257r2"},"outputs":[],"source":["class ClassifierWithTFEncoding(ClassifierWithBinaryEncoding):\n","\n","    _X = None\n","\n","    def __init__(self, model_cls):\n","        super().__init__(model_cls=model_cls)\n","    \n","    def get_dataset(\n","            self, file_list, num_words=1000\n","    ) -> Tuple[pd.DataFrame, List[int]]:\n","        \"\"\"\n","        Put your code for Q4(a) here. \n","\n","        Returns the tuple (X, y) where X is the feature set and y is the label.\n","        This method uses the term frequency encoding for features, where the most\n","        common 'num_words' number of terms are used. Further, this class should \n","        use the improved features from Q1(c) rather than the baseline we provided.\n","\n","        Args:\n","            file_list (List[int]): The list containing file names to process.\n","            num_words (int): The number of words (terms) to be used as features\n","              Note that the feature dataframe you create should have the number \n","              of columns the same as 'num_words'.\n","        \n","        Returns:\n","            X (pd.DataFrame), y (List[int])\n","        \"\"\"\n","        if self.X is not None and self.y is not None:\n","            return self.X, self.y\n","        \n","        X, y = None, None\n","        \n","        ####### TODO: Q4(a) #######\n","        # Use the term frequencies to construct the feature set.\n","        # You should only use 'num_words' number of terms as features, \n","        # which you should obtain by using any techniques covered in the IR lab (as in Q1(b)).\n","        #\n","        # Hint:\n","        #   Please remember to put index for your dataframe as the file name;\n","        #   columns should match with the terms used as features.\n","        #   For example: pd.DataFrame(data, index=[str(f) for f in file_list], columns=[...])\n","        \n","        ####################\n","        \n","        # Validate return types\n","        assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"incorrect return types\"\n","\n","        self.X = X; self.y = y\n","        return X, y\n","    \n","    @property\n","    def X(self):\n","        return ClassifierWithTFEncoding._X\n","    \n","    @X.setter\n","    def X(self, X):\n","        ClassifierWithTFEncoding._X = X"]},{"cell_type":"markdown","metadata":{"id":"M6SI69ASrOzU"},"source":["### Q4 (b)\n","\n","Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_D9ZdvG8WW1"},"outputs":[],"source":["q4 = ClassifierWithTFEncoding(LogisticRegression)\n","X_tf, y_tf = q4.get_dataset(ALL_FILES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOW0MGcb8kAl"},"outputs":[],"source":["train_mean_tf, train_low_tf, train_high_tf, test_mean_tf, test_low_tf, test_high_tf = Classifier.get_performance_ci(q4, X_tf, y_tf, num_tests=10)\n","print(f\"Average training accuracy over 10 random splits: {train_mean_tf}\")\n","print(f\"Confidence interval for training accuracy over 10 random splits: [{train_low_tf}, {train_high_tf}]\")\n","print(f\"Average test accuracy over 10 random splits: {test_mean_tf}\")\n","print(f\"Confidence interval for test accuracy over 10 random splits: [{test_low_tf}, {test_high_tf}]\")"]},{"cell_type":"markdown","metadata":{"id":"JB04-SIfrmKJ"},"source":["[Write your text answer here]"]},{"cell_type":"markdown","metadata":{"id":"a8X2vO-HrqwD"},"source":["## Q5: Comparison vs. Naive Bayes"]},{"cell_type":"markdown","metadata":{"id":"rBiV7VVjrvwq"},"source":["### Q5 (a)\n","\n","Implement a naive Bayes classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6YauwwDn89H1"},"outputs":[],"source":["def evaluate_nb(X, y, num_tests) -> Tuple[Classifier, Tuple]:\n","    train_mean, train_ci_low, train_ci_high, test_mean, test_ci_low, test_ci_high = [None] * 6\n","    nb_classifier: Classifier = None\n","\n","    ####### TODO: Q5(a) #######\n","    # Instantiate a Naive Bayes classifier and compute the train/test accuracies.\n","    # You should return the mean and the confidence bound of the train and test accuracies.\n","    #\n","    # Hint:\n","    #   Note that you can specify the classification algorithm when instantiating \n","    #   a Classifier object. Then, you can use the 'get_performance_ci' method.\n","\n","    ####################\n","    \n","    # Validate return types\n","    assert isinstance(nb_classifier, Classifier) and 'NB' in nb_classifier._model_cls.__name__, \"incorrect return types\"\n","    assert isinstance(train_mean, float) and isinstance(train_ci_low, float) and isinstance(train_ci_high, float), \"incorrect return types\"\n","    assert isinstance(test_mean, float) and isinstance(test_ci_low, float) and isinstance(test_ci_high, float), \"incorrect return types\"\n","\n","    return nb_classifier, (train_mean, train_ci_low, train_ci_high, test_mean, test_ci_low, test_ci_high)"]},{"cell_type":"markdown","metadata":{"id":"EB4FMYxZsz8W"},"source":["### Q5 (b)\n","\n","Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pom8530C9h8Y"},"outputs":[],"source":["nb_classifier, (train_mean_nb, train_low_nb, train_high_nb, test_mean_nb, test_low_nb, test_high_nb) = evaluate_nb(X_b_improved, y, num_tests=10)\n","print(f\"Average training accuracy over 10 random splits: {train_mean_nb}\")\n","print(f\"Confidence interval for training accuracy over 10 random splits: [{train_low_nb}, {train_high_nb}]\")\n","print(f\"Average test accuracy over 10 random splits: {test_mean_nb}\")\n","print(f\"Confidence interval for test accuracy over 10 random splits: [{test_low_nb}, {test_high_nb}]\")"]},{"cell_type":"markdown","metadata":{"id":"vMcY-FEwt0ZQ"},"source":["[Write your text answer here]"]},{"cell_type":"markdown","metadata":{"id":"O7F8PNFLt4yd"},"source":["## Q6: Binary Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"Od9x27NLt6_t"},"source":["### Q6 (a)\n","\n","Implement the *get_dataset* method of the *BinaryLogisticClassifier* class below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QZA5IaCB__OK"},"outputs":[],"source":["class BinaryLogisticClassifier(ClassifierWithImprovedBinaryEncoding):\n","\n","    _y = None\n","\n","    def __init__(self, model_cls):\n","        super().__init__(model_cls=model_cls)\n","    \n","    def get_dataset(\n","            self, file_list, num_words=1000\n","    ) -> Tuple[pd.DataFrame, List[int]]:\n","        \"\"\"\n","        Put your code for Q6(a) here. \n","\n","        Returns the tuple (X, y) where X is the feature set and y is the label.\n","        Use the improved binary encoding from Q1(c) for features, where the most\n","        common 'num_words' number of terms are used. \n","\n","        Args:\n","            file_list (List[int]): The list containing file names to process.\n","            num_words (int): The number of words (terms) to be used as features\n","              Note that the feature dataframe you create should have the number \n","              of columns the same as 'num_words'.\n","        \n","        Returns:\n","            X (pd.DataFrame), y (List[int])\n","        \"\"\"\n","        if self.X is not None and self.y is not None:\n","            return self.X, self.y\n","\n","        X, y = None, None\n","        \n","        ####### TODO: Q6(a) #######\n","        # Put your code below\n","        # Target values should be 1 for sci.med and 0 for any other labels.\n","        # Note:\n","        #   Please remember to put index for your dataframe as the file name;\n","        #   columns should match with the terms used as features.\n","        #   For example: pd.DataFrame(data, index=[str(f) for f in file_list], columns=[...])\n","        \n","        ####################\n","        \n","        # Validate return types\n","        assert isinstance(X, pd.DataFrame) and isinstance(y, list), \"incorrect return types\"\n","\n","        self.X = X; self.y = y\n","        return X, y\n","    \n","    @property\n","    def y(self):\n","        return BinaryLogisticClassifier._y\n","    \n","    @y.setter\n","    def y(self, y):\n","        BinaryLogisticClassifier._y = y"]},{"cell_type":"markdown","metadata":{"id":"_6tzIuYiubC4"},"source":["### Q6 (b)\n","\n","Use the following code to calculate the mean accuracy and 95% confidence interval over multiple random splits."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdH5PUx8Bf5e"},"outputs":[],"source":["q6 = BinaryLogisticClassifier(LogisticRegression)\n","X_bin, y_bin = q6.get_dataset(ALL_FILES, num_words=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_jpyu-x4CG7A"},"outputs":[],"source":["train_mean_bin, train_low_bin, train_high_bin, test_mean_bin, test_low_bin, test_high_bin = Classifier.get_performance_ci(q6, X_bin, y_bin, num_tests=10)\n","print(f\"Average training accuracy over 10 random splits: {train_mean_bin}\")\n","print(f\"Confidence interval for training accuracy over 10 random splits: [{train_low_bin}, {train_high_bin}]\")\n","print(f\"Average test accuracy over 10 random splits: {test_mean_bin}\")\n","print(f\"Confidence interval for test accuracy over 10 random splits: [{test_low_bin}, {test_high_bin}]\")\n"]},{"cell_type":"markdown","metadata":{"id":"-jW_XJ4Owckl"},"source":["[Write your text answer here]"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNi0RER8zNreKtABP4ndscM","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
